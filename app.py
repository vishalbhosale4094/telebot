import os
import asyncio
import logging
from flask import Flask, request, jsonify
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)

# --- Configuration ---
# It's best practice to use environment variables for sensitive data and deployment settings.
# On Render, you can set these in the "Environment" section of your service.
BOT_TOKEN = os.environ.get("BOT_TOKEN", "7843180063:AAFZFcKj-3QgxqQ_e97yKxfETK6CfCZ7ans")
# This should be the public URL of your Render web service.
WEBHOOK_URL = os.environ.get("WEBHOOK_URL", "https://medical-ai-chatbot-9nsp.onrender.com")

# Enable detailed logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- In-Memory Session Storage ---
# WARNING: This is for demonstration purposes only. In a real production environment
# like Render, the server can restart, wiping all data. For persistent history,
# you should use a database (like Redis, PostgreSQL, etc.).
user_histories = {}


# --- Bot Brain / Core Logic ---
# This function replaces your original /chat endpoint. It's now just a Python function.
def get_bot_response(user_message: str, history: list) -> dict:
    """
    This function simulates the AI backend. In your real app, this would
    be where you call your Gemini/LLM model.
    """
    logger.info(f"Generating response for: '{user_message}' with history length: {len(history)}")
    # This is the example response from your original code.
    # In a real scenario, this would be dynamically generated by your AI model.
    return {
        "response": f"Okay, I've received '{user_message}'. Can you describe the pain more specifically?",
        "Symptoms": "Headache",
        "Remedies": "Rest, drink plenty of water",
        "Precautions": "Avoid bright screens and loud noises",
        "Guidelines": "Maintain a regular sleep schedule",
        "medication": ["Ibuprofen", "Paracetamol"],
        "needs_follow_up": True,
        "follow_up_options": ["Forehead", "Back of Head", "All Over"],
        "Disclaimer": "I am an AI assistant, not a real doctor. Please consult a professional for medical advice.",
        "image_urls": [],  # Example: ["https://www.example.com/sample.jpg"]
    }


# --- Telegram Handlers ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handles the /start command."""
    user_id = update.effective_user.id
    user_histories[user_id] = []  # Reset history on /start
    await update.message.reply_text("üëã Welcome to MedAssist! Please describe your symptom.")


async def process_and_reply(update: Update, context: ContextTypes.DEFAULT_TYPE, text: str):
    """
    A refactored function to handle processing for both text messages and button callbacks.
    """
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    history = user_histories.get(user_id, [])

    # Show a "typing..." status to the user
    await context.bot.send_chat_action(chat_id=chat_id, action='typing')

    try:
        # Get the response from the bot's "brain"
        data = get_bot_response(text, history)

        # Build the reply message
        reply_parts = [f"üß† {data.get('response', '')}"]
        if data.get("Symptoms") and data["Symptoms"] != ".":
            reply_parts.append(f"ü©∫ *Symptoms:* {data['Symptoms']}")
        if data.get("Remedies"):
            reply_parts.append(f"üíä *Remedies:* {data['Remedies']}")
        if data.get("Precautions"):
            reply_parts.append(f"‚ö†Ô∏è *Precautions:* {data['Precautions']}")
        if data.get("Guidelines"):
            reply_parts.append(f"üìò *Guidelines:* {data['Guidelines']}")
        if data.get("medication"):
            reply_parts.append(f"üíä *Medication:* {', '.join(data['medication'])}")
        if data.get("Disclaimer"):
            reply_parts.append(f"üßæ *Disclaimer:* {data['Disclaimer']}")

        reply = "\n\n".join(reply_parts)

        # Update user history
        history.extend([
            {"role": "user", "parts": [text]},
            {"role": "model", "parts": [data.get('response', '')]}
        ])
        user_histories[user_id] = history

        # Prepare keyboard for follow-up questions
        markup = None
        if data.get("needs_follow_up") and data.get("follow_up_options"):
            keyboard = [[InlineKeyboardButton(opt, callback_data=opt)] for opt in data["follow_up_options"]]
            markup = InlineKeyboardMarkup(keyboard)

        # Send the response
        await update.effective_message.reply_text(reply, reply_markup=markup, parse_mode='Markdown')

        # Send any images
        if "image_urls" in data:
            for url in data["image_urls"]:
                await update.effective_message.reply_photo(url)

    except Exception as e:
        logger.error(f"Error processing message: {e}", exc_info=True)
        await update.effective_message.reply_text(
            "‚ö†Ô∏è An error occurred while processing your request. Please try again.")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handles regular text messages."""
    await process_and_reply(update, context, update.message.text)


async def handle_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handles button clicks (callback queries)."""
    query = update.callback_query
    await query.answer()  # Acknowledge the button press
    await process_and_reply(update, context, query.data)


# --- Flask App & Webhook Setup ---
# Initialize Flask app
flask_app = Flask(__name__)

# Initialize Telegram bot application
ptb_app = Application.builder().token(BOT_TOKEN).build()
ptb_app.add_handler(CommandHandler("start", start))
ptb_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
ptb_app.add_handler(CallbackQueryHandler(handle_button))


@flask_app.route('/')
def index():
    return "‚úÖ MedAssist Backend with Webhook is Running!"


@flask_app.route('/telegram', methods=['POST'])
async def telegram_webhook():
    """This is the webhook endpoint Telegram will call."""
    update_data = request.get_json()
    update = Update.de_json(update_data, ptb_app.bot)
    await ptb_app.process_update(update)
    return "OK", 200


async def setup_webhook():
    """Sets the webhook on application startup."""
    webhook_path = "/telegram"
    full_webhook_url = f"{WEBHOOK_URL}{webhook_path}"
    logger.info(f"Setting webhook to: {full_webhook_url}")
    await ptb_app.bot.set_webhook(url=full_webhook_url, allowed_updates=Update.ALL_TYPES)


# Main entry point
if __name__ == '__main__':
    # Set up the webhook when the application starts
    # This is an async function, so we need to run it in an event loop.
    asyncio.run(setup_webhook())

    # Run the Flask app
    # For production, use a proper WSGI server like Gunicorn or Waitress
    # Example: gunicorn -w 4 -k uvicorn.workers.UvicornWorker app:flask_app
    logger.info("Starting Flask server...")
    flask_app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)))